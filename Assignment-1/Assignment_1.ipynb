{"cells":[{"cell_type":"markdown","metadata":{"id":"Lo68A2ltMkJZ"},"source":["# ECE 570 Assignment 1\n","\n","## **Instructions**\n","1. Please follow the thread in Piazza for detailed usage of Google Colab.\n","2. All submissions should be uploaded to Gradescope as a pdf version of your current jupyter notebook. In this assignment you only need to submit sections 4 and 5.\n","3. Have fun!\n"]},{"cell_type":"markdown","metadata":{"id":"O0qw691FVGPi"},"source":["## 1. Background\n","In this assignment, we are trying to do simple sentiment analysis. Sentiment analysis is the process of detecting positive or negative sentiment in text. It’s often used by businesses to detect sentiment in social data, gauge brand reputation, and understand customers.\n","\n","The dataset we will be using is called [***Stanford Sentiment Treebank***](https://nlp.stanford.edu/sentiment/code.html). This dataset is collected from movie reviews on *Rotten Tomatoes* for over 20k sentences. All reviews later got re-organized as distinct phrases with label as number 0.0 to 1.0. Labels can later be divided in to five intervals [0, 0.2], (0.2, 0.4], (0.4, 0.6], (0.6, 0.8], (0.8, 1.0] which means very negative, negative, neutral, positive, very positive, respectively.\n","\n","The dataset we are using in this assignment is a subset of Stanford Sentiment Treebank and consists of **400 phrases**. Train-test dataset split ratio is 50/50 and for either train or test dataset, half of them are extremely positive reviews (have corresponding range (0.9, 1.0]), and the other half are extremely negative reviews (have corresponding range [0.0, 0.1]). Your job is to construct a simple function **train/reference from train dataset only** that takes a single phrase in and outputs whether this phrase has positive or negative sentiment."]},{"cell_type":"markdown","metadata":{"id":"IuRq9xvxNoX4"},"source":["## 2. Mounting your google drive on Colab\n","Since colab is running on a remote server on Google, you need to mount your google drive on Colab to serve as a 'local directory' to your coding environment. Luckily, it is as simple as two steps! Try to run this block and follow the instructions that pop out.\n","\n","Note: This part is not necessary if you are using your own Python environment or other remote python environment."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"pSTudka7I6gH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661833149965,"user_tz":240,"elapsed":1722,"user":{"displayName":"Souradip Pal","userId":"00022299520318460014"}},"outputId":"d062af4e-77a1-4c6f-9387-07862c966cb6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive \n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"iKX2M2NfOvPH"},"source":["## 3. Load data\n","Now, we need to load the data from the \"train.txt\" and \"test.txt\" file. Please change the location for **dir_root** in the following code block to where you saved all your files.\n","\n","Train dataset is stored in the \"train.txt\" file which stores 100 positive phrases and 100 negative phrases. Each line in the file is consist of a phrase and the corresponding sentiment positive(1) or negative(-1) followed by a separation mark '|'. \n","\n","Tips: It is helpful and sometimes necessary to have a separate folder for each assignment!"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"neQW_OYmI_me","executionInfo":{"status":"ok","timestamp":1661833149967,"user_tz":240,"elapsed":126,"user":{"displayName":"Souradip Pal","userId":"00022299520318460014"}}},"outputs":[],"source":["import os  \n","#########################        YOUR CODE        ######################### \n","dir_root = '/content/drive/MyDrive/ECE570/Assignment-1'        # change this root directory\n","#########################      END YOUR CODE      #########################                                                                           # for better path controls\n","train_dir = os.path.join(dir_root, 'train.txt')                                      # locate the train.txt file"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"B2dxJu94JQ8Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661833149969,"user_tz":240,"elapsed":124,"user":{"displayName":"Souradip Pal","userId":"00022299520318460014"}},"outputId":"70bc86c3-edbc-4e38-84ee-6917b5373a08"},"outputs":[{"output_type":"stream","name":"stdout","text":["Phrase \"Astonishingly skillful and moving\" has the sentiment 1\n","Phrase \"are incredibly beautiful to look at\" has the sentiment 1\n","Phrase \"as the most magical and most fun family fare of this or any recent holiday season\" has the sentiment 1\n","Phrase \"It shows that some studios firmly believe that people have lost the ability to think and will forgive any shoddy product as long as there 's a little girl-on-girl action .\" has the sentiment -1\n","Phrase \"Will assuredly rank as one of the cleverest , most deceptively amusing comedies of the year .\" has the sentiment 1\n","Phrase \"disintegrates into a dreary , humorless soap opera\" has the sentiment -1\n","Phrase \"The editing is chaotic , the photography grainy and badly focused , the writing unintentionally hilarious , the direction unfocused ,\" has the sentiment -1\n","Phrase \"The film is often filled with a sense of pure wonderment and excitement not often seen in today 's cinema du sarcasm\" has the sentiment 1\n","Phrase \"is as appalling as any ` comedy ' to ever spill from a projector 's lens\" has the sentiment -1\n","Phrase \"... could easily be called the best Korean film of 2002 .\" has the sentiment 1\n"]}],"source":["# use built-in function \"open\" to read files\n","f = open(train_dir, 'r')\n","train_lines = f.readlines()\n","f.close()\n","\n","# construct two lists to store phrases and labels seperately\n","train_data, train_label = [], []\n","for line in train_lines:\n","    line_sec = line.split(\"|\", -1)\n","    train_data.append(line_sec[0])\n","    train_label.append(int(line_sec[1]))\n","\n","# preview some data here\n","preview = 10                 # feel free to toggle this number to see more/less data\n","for i in range(preview):\n","    print(f'Phrase \\\"{train_data[i]}\\\" has the sentiment {train_label[i]}')"]},{"cell_type":"markdown","metadata":{"id":"hH3n1eHKhGm6"},"source":["## 4. Classifier (60/100 points)\n","Please fill in code in the provided skeleton for the function `sentiment_analysis` which has the following structure:\n","* Input: a single string `phrase`\n","* output: an integer `-1` or `1`. `-1` stands for negative sentiment and `1` stands for positive sentiment\n","\n","Notes:\n","1. Try to constrain your codes within **50 lines without importing any additional packages** (i.e, this assignment does not require you to perform any complicated model analysis)\n","2. You can view all the training phrases by opening file *'train.txt'* in the provided zip file.\n","3. Throughout the design of your algorithm, **you should only have access to the train dataset** stored in \"train.txt\". The test dataset stored in 'test.npy' should only be used in the next evaluation section. You can think that train dataset is what we would actually have to learn from (like course materials and lectures) while test is new data that simulates real-world posts (where we wouldn’t usually know the true labels). \n","\n","You might find the following hints helpful (not required to use them):\n","1. Part of frequency table for all words in the training dataset is given as the follow:\n","\n","Word | # of times in positive | # of times in negative | total #\n","--- | --- | --- | ---\n","best|12|0|12\n","i|0|11|11\n","are|9|1|10\n","most|9|1|10\n","bad|0|10|10\n","at|2|6|8\n","his|7|1|8\n","has|5|3|8\n","about|2|6|8\n","have|1|6|7\n","from|2|4|6\n","worst|0|6|6\n","does|2|4|6\n","brilliant|6|0|6\n","films|6|0|6\n","any|1|4|5\n","enough|1|4|5\n","what|4|1|5\n","work|5|0|5\n","great|4|1|5\n","time|1|4|5\n","or|1|3|4\n","some|1|3|4\n","will|3|1|4\n","sense|3|1|4\n","cinema|3|1|4\n","comedy|1|3|4\n","just|1|3|4\n","first|4|0|4\n","masterpiece|3|1|4\n","my|0|4|4\n","want|1|3|4\n","if|0|4|4\n","something|3|1|4\n","story|3|1|4\n","love|4|0|4\n","filmmaking|2|2|4\n","their|4|0|4\n","when|0|4|4\n","than|1|3|4\n","look|1|2|3\n","recent|3|0|3\n","product|0|3|3\n","into|0|3|3\n","hilarious|2|1|3\n","often|3|0|3\n","easily|3|0|3\n","performances|3|0|3\n","deserves|3|0|3\n","\n","2. Use the keyword `in`.\n","3. Use `lower()` or `upper()` function.\n","4. Run the cell below to dissect the frequency table more extensively.\n","5. Manually define your own criteria for good vs. bad review (e.g. you may want to consider words that are usually good or bad)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"vjxMurSkCpTm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661833149972,"user_tz":240,"elapsed":100,"user":{"displayName":"Souradip Pal","userId":"00022299520318460014"}},"outputId":"bced2ce1-0606-4de0-a5de-1669834457cd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('the', {'total': 119, 'pos': 54, 'neg': 65}),\n"," (',', {'total': 115, 'pos': 43, 'neg': 72}),\n"," ('a', {'total': 90, 'pos': 45, 'neg': 45}),\n"," ('.', {'total': 84, 'pos': 37, 'neg': 47}),\n"," ('of', {'total': 80, 'pos': 38, 'neg': 42}),\n"," ('and', {'total': 74, 'pos': 37, 'neg': 37}),\n"," ('to', {'total': 48, 'pos': 17, 'neg': 31}),\n"," ('is', {'total': 46, 'pos': 22, 'neg': 24}),\n"," ('that', {'total': 40, 'pos': 19, 'neg': 21}),\n"," (\"'s\", {'total': 39, 'pos': 18, 'neg': 21}),\n"," ('it', {'total': 30, 'pos': 11, 'neg': 19}),\n"," ('as', {'total': 29, 'pos': 13, 'neg': 16}),\n"," ('in', {'total': 28, 'pos': 14, 'neg': 14}),\n"," ('with', {'total': 27, 'pos': 12, 'neg': 15}),\n"," ('movie', {'total': 26, 'pos': 11, 'neg': 15}),\n"," ('film', {'total': 25, 'pos': 13, 'neg': 12}),\n"," ('an', {'total': 21, 'pos': 8, 'neg': 13}),\n"," ('this', {'total': 19, 'pos': 6, 'neg': 13}),\n"," ('for', {'total': 17, 'pos': 8, 'neg': 9}),\n"," ('all', {'total': 16, 'pos': 5, 'neg': 11}),\n"," ('like', {'total': 15, 'pos': 6, 'neg': 9}),\n"," ('one', {'total': 13, 'pos': 9, 'neg': 4}),\n"," ('not', {'total': 13, 'pos': 3, 'neg': 10}),\n"," ('be', {'total': 12, 'pos': 9, 'neg': 3}),\n"," ('best', {'total': 12, 'pos': 12, 'neg': 0}),\n"," ('its', {'total': 12, 'pos': 4, 'neg': 8}),\n"," ('you', {'total': 11, 'pos': 5, 'neg': 6}),\n"," ('i', {'total': 11, 'pos': 0, 'neg': 11}),\n"," ('are', {'total': 10, 'pos': 9, 'neg': 1}),\n"," ('most', {'total': 10, 'pos': 9, 'neg': 1}),\n"," ('bad', {'total': 10, 'pos': 0, 'neg': 10}),\n"," (\"n't\", {'total': 10, 'pos': 3, 'neg': 7}),\n"," ('--', {'total': 9, 'pos': 6, 'neg': 3}),\n"," ('at', {'total': 8, 'pos': 2, 'neg': 6}),\n"," ('...', {'total': 8, 'pos': 5, 'neg': 3}),\n"," ('so', {'total': 8, 'pos': 4, 'neg': 4}),\n"," ('out', {'total': 8, 'pos': 4, 'neg': 4}),\n"," ('his', {'total': 8, 'pos': 7, 'neg': 1}),\n"," ('has', {'total': 8, 'pos': 5, 'neg': 3}),\n"," ('about', {'total': 8, 'pos': 2, 'neg': 6}),\n"," ('on', {'total': 8, 'pos': 3, 'neg': 5}),\n"," (\"''\", {'total': 8, 'pos': 3, 'neg': 5}),\n"," ('have', {'total': 7, 'pos': 1, 'neg': 6}),\n"," ('year', {'total': 7, 'pos': 4, 'neg': 3}),\n"," ('even', {'total': 7, 'pos': 4, 'neg': 3}),\n"," ('from', {'total': 6, 'pos': 2, 'neg': 4}),\n"," ('worst', {'total': 6, 'pos': 0, 'neg': 6}),\n"," ('by', {'total': 6, 'pos': 3, 'neg': 3}),\n"," ('does', {'total': 6, 'pos': 2, 'neg': 4}),\n"," ('brilliant', {'total': 6, 'pos': 6, 'neg': 0}),\n"," ('such', {'total': 6, 'pos': 3, 'neg': 3}),\n"," ('who', {'total': 6, 'pos': 3, 'neg': 3}),\n"," ('films', {'total': 6, 'pos': 6, 'neg': 0}),\n"," ('any', {'total': 5, 'pos': 1, 'neg': 4}),\n"," ('there', {'total': 5, 'pos': 2, 'neg': 3}),\n"," ('little', {'total': 5, 'pos': 3, 'neg': 2}),\n"," ('ever', {'total': 5, 'pos': 2, 'neg': 3}),\n"," ('enough', {'total': 5, 'pos': 1, 'neg': 4}),\n"," ('no', {'total': 5, 'pos': 3, 'neg': 2}),\n"," ('what', {'total': 5, 'pos': 4, 'neg': 1}),\n"," ('every', {'total': 5, 'pos': 2, 'neg': 3}),\n"," ('see', {'total': 5, 'pos': 3, 'neg': 2}),\n"," ('work', {'total': 5, 'pos': 5, 'neg': 0}),\n"," ('great', {'total': 5, 'pos': 4, 'neg': 1}),\n"," ('time', {'total': 5, 'pos': 1, 'neg': 4}),\n"," ('or', {'total': 4, 'pos': 1, 'neg': 3}),\n"," ('some', {'total': 4, 'pos': 1, 'neg': 3}),\n"," ('will', {'total': 4, 'pos': 3, 'neg': 1}),\n"," ('comedies', {'total': 4, 'pos': 2, 'neg': 2}),\n"," ('sense', {'total': 4, 'pos': 3, 'neg': 1}),\n"," ('cinema', {'total': 4, 'pos': 3, 'neg': 1}),\n"," ('comedy', {'total': 4, 'pos': 1, 'neg': 3}),\n"," ('just', {'total': 4, 'pos': 1, 'neg': 3}),\n"," ('made', {'total': 4, 'pos': 2, 'neg': 2}),\n"," ('make', {'total': 4, 'pos': 1, 'neg': 3}),\n"," ('first', {'total': 4, 'pos': 4, 'neg': 0}),\n"," ('off', {'total': 4, 'pos': 2, 'neg': 2}),\n"," ('masterpiece', {'total': 4, 'pos': 3, 'neg': 1}),\n"," ('my', {'total': 4, 'pos': 0, 'neg': 4}),\n"," ('want', {'total': 4, 'pos': 1, 'neg': 3}),\n"," ('if', {'total': 4, 'pos': 0, 'neg': 4}),\n"," ('something', {'total': 4, 'pos': 3, 'neg': 1}),\n"," ('story', {'total': 4, 'pos': 3, 'neg': 1}),\n"," ('love', {'total': 4, 'pos': 4, 'neg': 0}),\n"," ('filmmaking', {'total': 4, 'pos': 2, 'neg': 2}),\n"," ('their', {'total': 4, 'pos': 4, 'neg': 0}),\n"," ('when', {'total': 4, 'pos': 0, 'neg': 4}),\n"," ('anyone', {'total': 4, 'pos': 2, 'neg': 2}),\n"," ('through', {'total': 4, 'pos': 2, 'neg': 2}),\n"," ('than', {'total': 4, 'pos': 1, 'neg': 3}),\n"," ('look', {'total': 3, 'pos': 1, 'neg': 2}),\n"," ('recent', {'total': 3, 'pos': 3, 'neg': 0}),\n"," ('product', {'total': 3, 'pos': 0, 'neg': 3}),\n"," ('into', {'total': 3, 'pos': 0, 'neg': 3}),\n"," ('hilarious', {'total': 3, 'pos': 2, 'neg': 1}),\n"," ('often', {'total': 3, 'pos': 3, 'neg': 0}),\n"," (\"'\", {'total': 3, 'pos': 1, 'neg': 2}),\n"," ('easily', {'total': 3, 'pos': 3, 'neg': 0}),\n"," ('performances', {'total': 3, 'pos': 3, 'neg': 0}),\n"," ('deserves', {'total': 3, 'pos': 3, 'neg': 0})]"]},"metadata":{},"execution_count":4}],"source":["# Create word frequency analysis\n","words = dict()\n","for phrase, label in zip(train_data, train_label):\n","    tokens = phrase.lower().split(' ')\n","    for t in tokens:\n","        if t not in words:\n","            words[t] = dict(total=0, pos=0,neg=0)\n","        words[t]['total'] += 1\n","        if label == 1:\n","            words[t]['pos'] += 1\n","        elif label == -1:\n","            words[t]['neg'] += 1\n","        else:\n","            raise RuntimeError('Label unknown')\n","sorted_word_list = sorted(words.items(), key=lambda item: item[1]['total'], reverse=True)\n","sorted_word_list[:100] # Show first 100 words"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"TNCrqyudK5NU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661833149975,"user_tz":240,"elapsed":80,"user":{"displayName":"Souradip Pal","userId":"00022299520318460014"}},"outputId":"88058ad2-95e0-4ad9-c7b4-d1a2eacbafca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Your method has the training accuracy of 99.5%\n"]}],"source":["def sentiment_analysis_model(phrase):\n","    \"\"\"\n","    sentiment_analysis function determines whether a phrase is positive (1) or negative (-1).\n","\n","    :param1(string) phrase: a single phrase in the format of string\n","    :return(int)          : 1 if the phrase is postive or -1 if the phrase is negative\n","    \"\"\" \n","\n","    #########################        YOUR CODE        ######################### \n","    tokens = phrase.lower().split(' ')\n","\n","    # positiveness = 1\n","    # for t in tokens:\n","    #     if t in words:\n","    #         pos = words[t]['pos']/words[t]['total']\n","    #         if pos > 0.9 or pos < 0.1:\n","    #             positiveness *= pos\n","        \n","    # if positiveness > 0.5:\n","    #     return 1\n","    # else: \n","    #     return -1\n","\n","    score = 0\n","    for t in tokens:\n","        if t in words:\n","            score += (words[t]['pos'] - words[t]['neg'])/words[t]['total']\n","    avg_score = score/len(tokens)\n","\n","    if avg_score > 0:\n","        return 1\n","    else:\n","        return -1\n","        \n","    #########################      END YOUR CODE      ######################### \n","\n","def evaluate(func, data, label):\n","\n","    score = 0\n","    for idx in range(len(data)):\n","        score += func(data[idx])==label[idx]\n","\n","    return score/len(data)\n","\n","train_acc = evaluate(sentiment_analysis_model, train_data, train_label)\n","print(f\"Your method has the training accuracy of {train_acc*100}%\")"]},{"cell_type":"markdown","metadata":{"id":"AadzsP3uRWib"},"source":["## 5. Evaluate (40/100 points)\n","You may already notice that there is an extra evaluation function in the above coding block which helps calculate the accuracy for your algorithm in the training dataset. The metric that we used to evaluate is straightforward:    \n","$$Accuracy = # of correct prediction / # of total cases$$\n","Now, let's test the performances of your algorithm in test dataset! \n","Try to get the **test accuracy** to be higher than 55% to receive **full credit**!\n","\n","Note: You should not have the accuracy to be lower than 50%!"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"JaoWgyj2K1TR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661833149978,"user_tz":240,"elapsed":59,"user":{"displayName":"Souradip Pal","userId":"00022299520318460014"}},"outputId":"293a513f-51f8-4994-97ad-ed1797c04d2b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Your method has the test accuracy of 72.0%\n"]}],"source":["import sys\n","sys.path.append(dir_root)\n","from top_classified_file import super_secret_function\n","\n","test_dir = os.path.join(dir_root, 'test.npy')\n","test_acc = super_secret_function(test_dir, sentiment_analysis_model)\n","\n","print(f\"Your method has the test accuracy of {test_acc*100}%\")"]},{"cell_type":"markdown","metadata":{"id":"CdSf3f-uS5jt"},"source":["## 6. Did you notice something interesting? (Optional)\n","1. During your design, does training accuracy always a little bit higher than test accuracy? Why?\n","2. Does the sentiment analysis task a little bit harder than you expected?\n","3. ... something else you would like to talk about"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Assignment_1.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}